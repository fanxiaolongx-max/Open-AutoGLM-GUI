#!/usr/bin/env python3
"""Detailed Gemini API connection test and diagnostics."""

import sys
import os
import time

# Add the project root to Python path
sys.path.insert(0, '/mnt/data/TOOL/Open-AutoGLM')

def test_openai_connection():
    """Test OpenAI compatible connection with detailed diagnostics."""
    try:
        from openai import OpenAI
        
        print("ğŸ”§ æµ‹è¯•OpenAIå…¼å®¹è¿æ¥...")
        print("-" * 50)
        
        # Test with different configurations
        configs = [
            {
                "name": "æ ‡å‡†é…ç½®",
                "base_url": "http://127.0.0.1:8045/v1",
                "api_key": "sk-985786ae787d43e6b8d42688f39ed83a",
                "timeout": 30
            },
            {
                "name": "é•¿è¶…æ—¶é…ç½®", 
                "base_url": "http://127.0.0.1:8045/v1",
                "api_key": "sk-985786ae787d43e6b8d42688f39ed83a",
                "timeout": 60
            }
        ]
        
        for config in configs:
            print(f"\nğŸ“‹ æµ‹è¯•é…ç½®: {config['name']}")
            print(f"   åœ°å€: {config['base_url']}")
            print(f"   è¶…æ—¶: {config['timeout']}ç§’")
            
            try:
                client = OpenAI(
                    base_url=config['base_url'],
                    api_key=config['api_key'],
                    timeout=config['timeout']
                )
                
                # Test 1: Models list
                print("   ğŸ” æµ‹è¯•1: è·å–æ¨¡å‹åˆ—è¡¨...")
                try:
                    start_time = time.time()
                    models = client.models.list()
                    elapsed = time.time() - start_time
                    print(f"   âœ… æ¨¡å‹åˆ—è¡¨è·å–æˆåŠŸ ({elapsed:.2f}ç§’)")
                    print(f"   ğŸ“Š å‘ç°æ¨¡å‹æ•°é‡: {len(models.data)}")
                    for model in models.data[:3]:  # Show first 3 models
                        print(f"      - {model.id}")
                except Exception as e:
                    print(f"   âŒ æ¨¡å‹åˆ—è¡¨è·å–å¤±è´¥: {e}")
                
                # Test 2: Chat completion
                print("   ğŸ” æµ‹è¯•2: èŠå¤©è¡¥å…¨...")
                try:
                    start_time = time.time()
                    response = client.chat.completions.create(
                        model="gemini-3-pro-high",
                        messages=[{"role": "user", "content": "Hello"}],
                        max_tokens=10,
                        temperature=0.1
                    )
                    elapsed = time.time() - start_time
                    print(f"   âœ… èŠå¤©è¡¥å…¨æˆåŠŸ ({elapsed:.2f}ç§’)")
                    if response.choices and len(response.choices) > 0:
                        content = response.choices[0].message.content
                        print(f"   ğŸ“ å“åº”å†…å®¹: {content}")
                    else:
                        print("   âš ï¸ å“åº”ä¸ºç©º")
                except Exception as e:
                    print(f"   âŒ èŠå¤©è¡¥å…¨å¤±è´¥: {e}")
                
                # Test 3: Simple ping
                print("   ğŸ” æµ‹è¯•3: ç®€å•è¿æ¥æµ‹è¯•...")
                try:
                    import requests
                    start_time = time.time()
                    response = requests.get(f"{config['base_url']}/models", timeout=10)
                    elapsed = time.time() - start_time
                    print(f"   âœ… HTTPè¿æ¥æµ‹è¯•æˆåŠŸ ({elapsed:.2f}ç§’)")
                    print(f"   ğŸ“Š çŠ¶æ€ç : {response.status_code}")
                    if response.status_code == 200:
                        data = response.json()
                        if 'data' in data:
                            print(f"   ğŸ“Š æ¨¡å‹æ•°é‡: {len(data['data'])}")
                except Exception as e:
                    print(f"   âŒ HTTPè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
                
            except Exception as e:
                print(f"   âŒ å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: {e}")
        
        return True
        
    except ImportError:
        print("âŒ OpenAIåº“æœªå®‰è£…")
        return False
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
        return False

def test_model_service_manager():
    """Test the ModelServicesManager test_service method."""
    try:
        from gui_app.model_services import ModelServicesManager, ModelServiceConfig
        
        print("\nğŸ”§ æµ‹è¯•æ¨¡å‹æœåŠ¡ç®¡ç†å™¨...")
        print("-" * 50)
        
        manager = ModelServicesManager()
        
        # Get Gemini service
        gemini_service = None
        for service in manager.get_all_services():
            if service.id == "gemini_antigravity":
                gemini_service = service
                break
        
        if not gemini_service:
            # Try to find it in presets
            for preset in manager.get_preset_templates():
                if preset.id == "gemini_antigravity":
                    gemini_service = preset
                    break
        
        if not gemini_service:
            print("âŒ æœªæ‰¾åˆ°GeminiæœåŠ¡é…ç½®")
            return False
        
        print(f"ğŸ“‹ æœåŠ¡ä¿¡æ¯:")
        print(f"   åç§°: {gemini_service.name}")
        print(f"   åœ°å€: {gemini_service.base_url}")
        print(f"   æ¨¡å‹: {gemini_service.model_name}")
        print(f"   å¯†é’¥: {gemini_service.api_key[:8]}...")
        
        # Test the service
        print("\nğŸ” è°ƒç”¨test_serviceæ–¹æ³•...")
        success, message = manager.test_service(gemini_service)
        print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
        print(f"ğŸ“ è¿”å›æ¶ˆæ¯: {message}")
        
        return success
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æœåŠ¡ç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_direct_gemini():
    """Test direct Gemini API call."""
    try:
        import google.generativeai as genai
        
        print("\nğŸ”§ æµ‹è¯•ç›´æ¥Gemini API...")
        print("-" * 50)
        
        genai.configure(
            api_key="sk-985786ae787d43e6b8d42688f39ed83a",
            transport='rest',
            client_options={'api_endpoint': 'http://127.0.0.1:8045'}
        )
        
        model = genai.GenerativeModel('gemini-3-pro-high')
        
        print("ğŸ” å‘é€æµ‹è¯•è¯·æ±‚...")
        start_time = time.time()
        response = model.generate_content("Hello, respond with just 'OK'")
        elapsed = time.time() - start_time
        
        print(f"âœ… ç›´æ¥APIè°ƒç”¨æˆåŠŸ ({elapsed:.2f}ç§’)")
        print(f"ğŸ“ å“åº”: {response.text}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç›´æ¥APIè°ƒç”¨å¤±è´¥: {e}")
        return False

def main():
    """Run all diagnostic tests."""
    print("ğŸš€ Gemini API è¿æ¥è¯Šæ–­")
    print("=" * 60)
    
    results = []
    
    # Test 1: Direct Gemini API
    results.append(("ç›´æ¥Gemini API", test_direct_gemini()))
    
    # Test 2: OpenAI compatible connection
    results.append(("OpenAIå…¼å®¹æ¥å£", test_openai_connection()))
    
    # Test 3: Model service manager
    results.append(("æ¨¡å‹æœåŠ¡ç®¡ç†å™¨", test_model_service_manager()))
    
    print("\n" + "=" * 60)
    print("ğŸ“Š è¯Šæ–­ç»“æœæ€»ç»“:")
    for test_name, success in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"   {test_name}: {status}")
    
    if all(success for _, success in results):
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è¿æ¥åº”è¯¥æ­£å¸¸ã€‚")
        print("å¦‚æœGUIä¸­ä»ç„¶æ˜¾ç¤ºå¤±è´¥ï¼Œå¯èƒ½æ˜¯ç•Œé¢æ›´æ–°é—®é¢˜ã€‚")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ’æŸ¥ã€‚")
        print("å»ºè®®æ£€æŸ¥:")
        print("1. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("2. Antigravityä»£ç†æœåŠ¡æ˜¯å¦è¿è¡Œ")
        print("3. APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
        print("4. é˜²ç«å¢™è®¾ç½®æ˜¯å¦é˜»æ­¢è¿æ¥")

if __name__ == "__main__":
    main()
