#!/usr/bin/env python3
"""Test Gemini API configuration with Antigravity proxy."""

import sys
import os

# Add the project root to Python path
sys.path.insert(0, '/mnt/data/TOOL/Open-AutoGLM')

def test_gemini_direct():
    """Test direct Gemini API call using the provided script."""
    try:
        import google.generativeai as genai
        
        print("ğŸ”§ æµ‹è¯•ç›´æ¥Gemini APIè°ƒç”¨...")
        
        # ä½¿ç”¨ Antigravity ä»£ç†åœ°å€ (æ¨è 127.0.0.1)
        genai.configure(
            api_key="sk-985786ae787d43e6b8d42688f39ed83a",
            transport='rest',
            client_options={'api_endpoint': 'http://127.0.0.1:8045'}
        )
        
        model = genai.GenerativeModel('gemini-3-pro-high')
        response = model.generate_content("Hello, please respond in Chinese: ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")
        print(f"âœ… Gemini API å“åº”: {response.text}")
        return True
        
    except ImportError:
        print("âŒ éœ€è¦å®‰è£… google-generativeai: pip install google-generativeai")
        return False
    except Exception as e:
        print(f"âŒ Gemini API è°ƒç”¨å¤±è´¥: {e}")
        return False

def test_gemini_openai_compat():
    """Test Gemini API through OpenAI compatible interface."""
    try:
        from openai import OpenAI
        
        print("\nğŸ”§ æµ‹è¯•OpenAIå…¼å®¹æ¥å£è°ƒç”¨Gemini...")
        
        client = OpenAI(
            base_url="http://127.0.0.1:8045/v1",
            api_key="sk-985786ae787d43e6b8d42688f39ed83a"
        )
        
        response = client.chat.completions.create(
            model="gemini-3-pro-high",
            messages=[
                {"role": "user", "content": "Hello, please respond in Chinese: ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}
            ],
            max_tokens=500,
            temperature=0.7
        )
        
        if response and response.choices and len(response.choices) > 0:
            content = response.choices[0].message.content
            print(f"âœ… OpenAIå…¼å®¹æ¥å£å“åº”: {content}")
            return True
        else:
            print("âŒ OpenAIå…¼å®¹æ¥å£å“åº”ä¸ºç©º")
            return False
        
    except ImportError:
        print("âŒ éœ€è¦å®‰è£… openai: pip install openai")
        return False
    except Exception as e:
        print(f"âŒ OpenAIå…¼å®¹æ¥å£è°ƒç”¨å¤±è´¥: {e}")
        return False

def test_model_service_config():
    """Test the model service configuration."""
    try:
        from gui_app.model_services import ModelServicesManager, ModelServiceConfig
        
        print("\nğŸ”§ æµ‹è¯•æ¨¡å‹æœåŠ¡é…ç½®...")
        
        manager = ModelServicesManager()
        
        # Check if Gemini preset is available
        gemini_service = None
        for service in manager.get_preset_templates():
            if service.id == "gemini_antigravity":
                gemini_service = service
                break
        
        if gemini_service:
            print(f"âœ… æ‰¾åˆ°Geminié¢„ç½®é…ç½®:")
            print(f"   åç§°: {gemini_service.name}")
            print(f"   åœ°å€: {gemini_service.base_url}")
            print(f"   æ¨¡å‹: {gemini_service.model_name}")
            print(f"   APIå¯†é’¥: {gemini_service.api_key[:8]}...")
            
            # Test the service
            success, message = manager.test_service(gemini_service)
            if success:
                print(f"âœ… æœåŠ¡æµ‹è¯•æˆåŠŸ: {message}")
                return True
            else:
                print(f"âŒ æœåŠ¡æµ‹è¯•å¤±è´¥: {message}")
                return False
        else:
            print("âŒ æœªæ‰¾åˆ°Geminié¢„ç½®é…ç½®")
            return False
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹æœåŠ¡é…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """Run all tests."""
    print("ğŸš€ å¼€å§‹æµ‹è¯•Gemini APIé…ç½®...")
    print("=" * 60)
    
    results = []
    
    # Test 1: Direct Gemini API
    results.append(test_gemini_direct())
    
    # Test 2: OpenAI compatible interface
    results.append(test_gemini_openai_compat())
    
    # Test 3: Model service configuration
    results.append(test_model_service_config())
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"   ç›´æ¥APIè°ƒç”¨: {'âœ… é€šè¿‡' if results[0] else 'âŒ å¤±è´¥'}")
    print(f"   OpenAIå…¼å®¹æ¥å£: {'âœ… é€šè¿‡' if results[1] else 'âŒ å¤±è´¥'}")
    print(f"   æ¨¡å‹æœåŠ¡é…ç½®: {'âœ… é€šè¿‡' if results[2] else 'âŒ å¤±è´¥'}")
    
    if all(results):
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Gemini APIé…ç½®æ­£å¸¸ã€‚")
        return 0
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")
        return 1

if __name__ == "__main__":
    sys.exit(main())
