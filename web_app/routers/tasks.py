# -*- coding: utf-8 -*-
"""
Tasks API router.
"""

from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks
from pydantic import BaseModel
from typing import Optional
import logging

from web_app.auth import verify_token
from web_app.services.task_service import task_service

# è®¾ç½®è¯¦ç»†æ—¥å¿—
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# ç¡®ä¿æœ‰æ§åˆ¶å°è¾“å‡º
if not logger.handlers:
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.DEBUG)
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

router = APIRouter(prefix="/api/tasks", tags=["tasks"])


class RunTaskRequest(BaseModel):
    task_content: str
    device_ids: list[str]
    model_settings: Optional[dict] = None
    send_email: Optional[bool] = True  # Default True for backward compatibility
    no_auto_lock: Optional[bool] = False  # å¤æ‚ä»»åŠ¡æ¨¡å¼ä¸‹ä¸è‡ªåŠ¨é”å±
    restore_lock_to_state: Optional[bool] = None  # æ˜ç¡®æŒ‡å®šè¦æ¢å¤çš„é”å±çŠ¶æ€ï¼ˆç”¨äºå­ä»»åŠ¡é“¾ï¼‰
    task_type: Optional[str] = "manual"  # ä»»åŠ¡ç±»å‹: chat/scheduled/manual
    force_run: Optional[bool] = False  # æ˜¯å¦å¼ºåˆ¶æ‰§è¡Œï¼ˆæ‰“æ–­å½“å‰ä»»åŠ¡ï¼‰
    session_id: Optional[str] = None  # èŠå¤©ä¼šè¯ IDï¼ˆç”¨äºåœ¨åŒä¸€ä¼šè¯ä¸­å‘é€å¤šä¸ªæ¶ˆæ¯ï¼‰
    message_id: Optional[str] = None  # æ¶ˆæ¯ IDï¼ˆç”¨äºç»‘å®šæ—¥å¿—å’Œæˆªå›¾ï¼‰
    debug_mode: Optional[bool] = False  # è°ƒè¯•æ¨¡å¼ï¼šç‚¹å‡»å‰æ˜¾ç¤ºé¢„è§ˆ


class DecomposeTaskRequest(BaseModel):
    task_content: str


class TaskResponse(BaseModel):
    id: str
    task_content: str
    device_ids: list[str]
    status: str
    start_time: str
    end_time: str = ""
    results: list = []
    logs: list = []
    progress: int = 0
    initial_lock_state: Optional[bool] = None  # Initial lock state detected (for subtask chains)


class TaskStatusResponse(BaseModel):
    running: bool
    task: Optional[TaskResponse] = None


@router.post("/decompose")
async def decompose_task(
    request: DecomposeTaskRequest,
    _: bool = Depends(verify_token)
):
    """
    å°†å¤æ‚ä»»åŠ¡æ‹†è§£æˆtodolistã€‚
    ä½¿ç”¨å½“å‰æ¿€æ´»çš„æ¨¡å‹æœåŠ¡è¿›è¡Œä»»åŠ¡æ‹†è§£ã€‚
    """
    from web_app.services.model_service import model_service
    from openai import OpenAI
    import json

    active_model = model_service.get_active_service()
    if not active_model:
        raise HTTPException(status_code=400, detail="No active model service configured")

    # æ„å»ºä»»åŠ¡æ‹†è§£çš„æç¤ºè¯
    decompose_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä»»åŠ¡åˆ†è§£ä¸“å®¶ã€‚è¯·å°†ç”¨æˆ·çš„å¤æ‚ä»»åŠ¡æ‹†è§£æˆä¸€ç³»åˆ—å¯ä»¥åœ¨æ‰‹æœºä¸Šé€æ­¥æ‰§è¡Œçš„ç®€å•å­ä»»åŠ¡ã€‚

ç”¨æˆ·çš„ä»»åŠ¡: {request.task_content}

è¯·å°†ä»»åŠ¡æ‹†è§£æˆä¸€ä¸ªJSONæ ¼å¼çš„å¾…åŠæ¸…å•ï¼Œæ¯ä¸ªå­ä»»åŠ¡åº”è¯¥æ˜¯ä¸€ä¸ªç‹¬ç«‹å¯æ‰§è¡Œçš„æ‰‹æœºæ“ä½œæŒ‡ä»¤ã€‚

**ä¸¥æ ¼æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–æ–‡å­—ï¼š**
{{
    "todoList": [
        {{"content": "å­ä»»åŠ¡1çš„å…·ä½“æ“ä½œæŒ‡ä»¤"}},
        {{"content": "å­ä»»åŠ¡2çš„å…·ä½“æ“ä½œæŒ‡ä»¤"}},
        {{"content": "å­ä»»åŠ¡3çš„å…·ä½“æ“ä½œæŒ‡ä»¤"}}
    ]
}}

æ³¨æ„ï¼š
1. æ¯ä¸ªå­ä»»åŠ¡åº”è¯¥æ˜¯å…·ä½“ã€å¯æ‰§è¡Œçš„æ‰‹æœºæ“ä½œï¼Œä¾‹å¦‚"æ‰“å¼€å¾®ä¿¡"ã€"ç‚¹å‡»æœç´¢æ¡†"ã€"è¾“å…¥XXX"ç­‰
2. å­ä»»åŠ¡æ•°é‡ä¸€èˆ¬åœ¨3-10ä¸ªä¹‹é—´
3. ç¡®ä¿ä»»åŠ¡æŒ‰æ­£ç¡®çš„æ‰§è¡Œé¡ºåºæ’åˆ—
4. åªè¿”å›JSONï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡Šæ–‡å­—"""

    try:
        # æ ¹æ®åè®®ç±»å‹ä½¿ç”¨ä¸åŒçš„å®¢æˆ·ç«¯
        logger.info("=" * 80)
        logger.info("[ä»»åŠ¡æ‹†è§£] å¼€å§‹è¯·æ±‚æ¨¡å‹...")
        logger.info(f"[è¯·æ±‚é…ç½®] base_url: {active_model.base_url}")
        logger.info(f"[è¯·æ±‚é…ç½®] model_name: {active_model.model_name}")
        logger.info(f"[è¯·æ±‚é…ç½®] protocol: {active_model.protocol}")
        logger.info(f"[è¯·æ±‚é…ç½®] api_key: {active_model.api_key[:10]}...{active_model.api_key[-4:]}" if active_model.api_key else "[è¯·æ±‚é…ç½®] api_key: None")
        logger.info("-" * 40)
        logger.info(f"[è¯·æ±‚æç¤ºè¯]\n{decompose_prompt}")
        logger.info("-" * 40)

        protocol = (active_model.protocol or "openai").lower()
        content = ""
        tokens = 0

        if protocol == "gemini":
            # ä½¿ç”¨ Gemini SDK
            try:
                import google.generativeai as genai
            except ImportError:
                raise HTTPException(status_code=500, detail="google-generativeai package not installed")

            base_url = active_model.base_url.rstrip('/') if active_model.base_url else ""
            if base_url.endswith('/v1'):
                base_url = base_url[:-3]
            is_official = not base_url or "googleapis.com" in base_url

            if is_official:
                genai.configure(api_key=active_model.api_key)
            else:
                genai.configure(
                    api_key=active_model.api_key,
                    transport='rest',
                    client_options={'api_endpoint': base_url}
                )

            logger.info("[APIè°ƒç”¨] æ­£åœ¨å‘é€è¯·æ±‚åˆ° Gemini æ¨¡å‹...")
            model = genai.GenerativeModel(active_model.model_name)
            response = model.generate_content(decompose_prompt)
            content = response.text if response.text else ""
            logger.info("[APIè°ƒç”¨] æ”¶åˆ° Gemini å“åº”")

        elif protocol == "anthropic":
            # ä½¿ç”¨ Anthropic SDK
            try:
                import anthropic
            except ImportError:
                raise HTTPException(status_code=500, detail="anthropic package not installed")

            base_url = active_model.base_url.rstrip('/')
            if base_url.endswith('/messages'):
                base_url = base_url[:-9]

            client = anthropic.Anthropic(
                api_key=active_model.api_key or "EMPTY",
                base_url=base_url,
            )

            logger.info("[APIè°ƒç”¨] æ­£åœ¨å‘é€è¯·æ±‚åˆ° Anthropic æ¨¡å‹...")
            response = client.messages.create(
                model=active_model.model_name,
                max_tokens=2000,
                messages=[{"role": "user", "content": decompose_prompt}],
            )
            content = response.content[0].text if response.content else ""
            tokens = response.usage.input_tokens + response.usage.output_tokens if response.usage else 0
            logger.info("[APIè°ƒç”¨] æ”¶åˆ° Anthropic å“åº”")

        else:
            # é»˜è®¤ä½¿ç”¨ OpenAI åè®®
            client = OpenAI(base_url=active_model.base_url, api_key=active_model.api_key)

            logger.info("[APIè°ƒç”¨] æ­£åœ¨å‘é€è¯·æ±‚åˆ°æ¨¡å‹...")
            response = client.chat.completions.create(
                model=active_model.model_name,
                messages=[{"role": "user", "content": decompose_prompt}],
                max_tokens=2000,
                temperature=0.3,
            )
            content = response.choices[0].message.content if response.choices else ""
            tokens = response.usage.total_tokens if response.usage else 0
            logger.info("[APIè°ƒç”¨] æ”¶åˆ°æ¨¡å‹å“åº”")

        logger.info("-" * 40)
        logger.info(f"[å“åº”åŸå§‹å†…å®¹] (é•¿åº¦: {len(content)})")
        logger.info(content)
        logger.info("-" * 40)
        logger.info(f"[Tokenä½¿ç”¨é‡] {tokens}")

        # è§£æJSON
        try:
            # å°è¯•ç›´æ¥è§£æ
            logger.info("[è§£æ] å°è¯•ç›´æ¥è§£æJSON...")
            result = json.loads(content)
            logger.info("[è§£æ] ç›´æ¥è§£ææˆåŠŸ!")
        except json.JSONDecodeError as parse_error:
            logger.warning(f"[è§£æ] ç›´æ¥è§£æå¤±è´¥: {parse_error}")
            # å°è¯•ä»markdownä»£ç å—ä¸­æå–
            import re
            logger.info("[è§£æ] å°è¯•ä»markdownä»£ç å—æå–...")
            json_match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', content)
            if json_match:
                extracted = json_match.group(1)
                logger.info(f"[è§£æ] ä»ä»£ç å—æå–å†…å®¹: {extracted[:200]}...")
                result = json.loads(extracted)
                logger.info("[è§£æ] ä»£ç å—è§£ææˆåŠŸ!")
            else:
                # å°è¯•æ‰¾åˆ° { å¼€å§‹çš„å†…å®¹
                logger.info("[è§£æ] å°è¯•æŸ¥æ‰¾ {{...}} ç»“æ„...")
                start = content.find('{')
                end = content.rfind('}')
                logger.info(f"[è§£æ] æ‰¾åˆ°ä½ç½®: start={start}, end={end}")
                if start != -1 and end != -1:
                    json_str = content[start:end+1]
                    logger.info(f"[è§£æ] æå–çš„JSONå­—ç¬¦ä¸²: {json_str[:500]}...")
                    result = json.loads(json_str)
                    logger.info("[è§£æ] JSONè§£ææˆåŠŸ!")
                else:
                    logger.error("[è§£æå¤±è´¥] æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„JSONç»“æ„!")
                    logger.error(f"[è§£æå¤±è´¥] å®Œæ•´å“åº”å†…å®¹:\n{content}")
                    raise HTTPException(status_code=500, detail="Failed to parse todoList from model response")

        todo_list = result.get("todoList", [])
        logger.info(f"[ç»“æœ] è§£æåˆ° {len(todo_list)} ä¸ªå­ä»»åŠ¡")
        for i, item in enumerate(todo_list):
            logger.info(f"  [{i+1}] {item.get('content', item)}")

        if not todo_list:
            logger.error("[é”™è¯¯] todoList ä¸ºç©º!")
            raise HTTPException(status_code=500, detail="Empty todoList returned")

        logger.info("[ä»»åŠ¡æ‹†è§£] å®Œæˆ!")
        logger.info("=" * 80)

        return {
            "success": True,
            "todoList": todo_list,
            "tokens": tokens
        }

    except json.JSONDecodeError as e:
        logger.error(f"[JSONè§£æé”™è¯¯] {str(e)}")
        logger.error(f"[JSONè§£æé”™è¯¯] åŸå§‹å†…å®¹: {content if 'content' in dir() else 'N/A'}")
        raise HTTPException(status_code=500, detail=f"Failed to parse model response: {str(e)}")
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[APIé”™è¯¯] ç±»å‹: {type(e).__name__}")
        logger.error(f"[APIé”™è¯¯] è¯¦æƒ…: {str(e)}")
        import traceback
        logger.error(f"[APIé”™è¯¯] å †æ ˆ:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Model API error: {str(e)}")


@router.post("/run")
async def run_task(
    request: RunTaskRequest,
    background_tasks: BackgroundTasks,
    _: bool = Depends(verify_token)
):
    """
    Run a task on specified devices.

    This starts the task in the background and returns immediately.
    Use /api/tasks/status to check progress or connect via WebSocket for real-time updates.
    """
    task_type = request.task_type or "manual"
    force_run = request.force_run or False

    # Check if a task is already running
    current = task_service.get_current_task()
    if current:
        # æ£€æŸ¥ä¼˜å…ˆçº§
        can_interrupt, current_info = task_service.can_interrupt_current_task(task_type)

        if not force_run:
            # è¿”å›å†²çªä¿¡æ¯ï¼Œè®©å‰ç«¯å†³å®šæ˜¯å¦å¼ºåˆ¶æ‰§è¡Œ
            raise HTTPException(
                status_code=409,
                detail={
                    "message": "A task is already running",
                    "can_interrupt": can_interrupt,
                    "current_task": current_info,
                    "new_task_type": task_type,
                }
            )
        else:
            # å¼ºåˆ¶æ‰§è¡Œï¼šå…ˆåœæ­¢å½“å‰ä»»åŠ¡
            if can_interrupt:
                logger.info(f"Force stopping current task {current.id} for higher priority task")
                await task_service.stop_all_tasks()
                # ç­‰å¾…ä»»åŠ¡åœæ­¢
                import asyncio
                await asyncio.sleep(1)
            else:
                # ä¸èƒ½æ‰“æ–­ï¼ˆæ–°ä»»åŠ¡ä¼˜å…ˆçº§ä¸å¤Ÿé«˜ï¼‰
                raise HTTPException(
                    status_code=409,
                    detail={
                        "message": "Cannot interrupt: new task has lower or equal priority",
                        "can_interrupt": False,
                        "current_task": current_info,
                        "new_task_type": task_type,
                    }
                )

    if not request.device_ids:
        raise HTTPException(status_code=400, detail="No devices specified")

    # Start task in background
    async def run_in_background():
        try:
            result = await task_service.run_task(
                task_content=request.task_content,
                device_ids=request.device_ids,
                model_config=request.model_settings,
                send_email=request.send_email if request.send_email is not None else True,
                no_auto_lock=request.no_auto_lock if request.no_auto_lock is not None else False,
                restore_lock_to_state=request.restore_lock_to_state,
                task_type=task_type,
                session_id=request.session_id,
                message_id=request.message_id,
                debug_mode=request.debug_mode if request.debug_mode is not None else False,
            )
            # Note: task_finished is already broadcast via _emit_finished callback in task_service
            # No need to call broadcast_task_finished here again
        except Exception as e:
            # Broadcast error only if task_service didn't handle it
            from web_app.routers.websocket import broadcast_task_finished
            await broadcast_task_finished("", False, f"Task failed: {str(e)}", None)

    background_tasks.add_task(run_in_background)

    return {
        "success": True,
        "message": "Task started",
        "task_content": request.task_content,
        "device_ids": request.device_ids,
        "task_type": task_type,
    }


@router.post("/stop")
async def stop_tasks(_: bool = Depends(verify_token)):
    """Stop all running tasks."""
    success = await task_service.stop_all_tasks()
    return {"success": success, "message": "Stop signal sent"}


@router.get("/status", response_model=TaskStatusResponse)
async def get_task_status(_: bool = Depends(verify_token)):
    """Get current task status."""
    status = task_service.get_task_status()
    return TaskStatusResponse(
        running=status["running"],
        task=TaskResponse(**status["task"]) if status["task"] else None
    )


@router.get("/history")
async def get_task_history(
    limit: int = 10,
    _: bool = Depends(verify_token)
):
    """Get recent task history."""
    history = task_service.get_task_history(limit)
    return {"tasks": history}


class ComplexTaskEmailRequest(BaseModel):
    task_name: str
    subtasks: list[dict]  # [{content: str, status: str, logs: list}]
    total_tokens: int = 0
    screenshot_id: Optional[str] = None  # ä½¿ç”¨ screenshot_id è€Œä¸æ˜¯ base64


@router.post("/send-complex-email")
async def send_complex_task_email(
    request: ComplexTaskEmailRequest,
    _: bool = Depends(verify_token)
):
    """Send email report for complex task completion."""
    from web_app.services.email_service import email_service

    # Build details from subtasks
    details_lines = []
    success_count = 0
    failed_count = 0

    for i, subtask in enumerate(request.subtasks, 1):
        status_icon = "âœ…" if subtask.get("status") == "completed" else "âŒ"
        details_lines.append(f"{status_icon} å­ä»»åŠ¡ {i}: {subtask.get('content', '')}")
        if subtask.get("logs"):
            for log in subtask["logs"][-3:]:  # Only last 3 logs per subtask
                details_lines.append(f"    {log}")
        if subtask.get("status") == "completed":
            success_count += 1
        else:
            failed_count += 1

    if request.total_tokens > 0:
        details_lines.append(f"\nğŸ“Š æ€»Tokenæ¶ˆè€—: {request.total_tokens}")

    details = "\n".join(details_lines)

    # ä»æ•°æ®åº“è·å–æˆªå›¾æ•°æ®ï¼ˆå¦‚æœæä¾›äº† screenshot_idï¼‰
    screenshot_data = None
    if request.screenshot_id:
        try:
            from web_app.services.chat_service import chat_service
            screenshot_data = chat_service.get_screenshot(request.screenshot_id)
        except Exception as e:
            logger.error(f"Failed to get screenshot {request.screenshot_id}: {e}")

    success, message = email_service.send_task_report(
        task_name=f"[å¤æ‚ä»»åŠ¡] {request.task_name[:40]}",
        success_count=success_count,
        failed_count=failed_count,
        total_count=len(request.subtasks),
        details=details,
        screenshot_data=screenshot_data,
        is_scheduled=False
    )

    return {"success": success, "message": message}
